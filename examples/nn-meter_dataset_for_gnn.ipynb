{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latency Dataset - GNN Model\n",
    "\n",
    "Considering the dataset is encoded in a graph format, here is an example of using GNN to predict the model latency with the bench dataset. \n",
    "\n",
    "In the previous work of [BRP-NAS](https://arxiv.org/abs/2007.08668v2), the authors propose an end-to-end latency predictor which consists of a GCN. Their GCN predictor demonstrates significant improvement over the layer-wise predictor on [NAS-Bench-201](https://arxiv.org/abs/2001.00326). While on our bench dataset, the preformance of BRP-NAS is consistently poor. As discussed in our paper, the reason is the model graph difference between training and testing set. GNN learns the representation of model graphs. Although the models in our bench dataset have largely overlapped operator types, the operator configurations, edges, and model latency ranges are different.\n",
    "\n",
    "To better deal with the problems above, we give a GNN example with graph representation improved. We first build our GNN model, which is constructed based on GraphSAGE, and maxpooling is selected as out pooling method. Next, we will start training after the data is loaded. `GNNDataset` and `GNNDataloader` in `nn_meter/dataset/gnn_dataloader.py` build the model structure of the Dataset in `.jsonl` format into our required Dataset and Dataloader. \n",
    "\n",
    "Let's start our journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Build our GraphSAGE Model\n",
    "\n",
    "We built our model with the help of DGL library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "from dgl.nn.pytorch.glob import MaxPooling\n",
    "import dgl.nn as dglnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "class GNN(Module):\n",
    "    def __init__(self, \n",
    "                num_features=0, \n",
    "                num_layers=2,\n",
    "                num_hidden=32,\n",
    "                dropout_ratio=0):\n",
    "\n",
    "        super(GNN, self).__init__()\n",
    "        self.nfeat = num_features\n",
    "        self.nlayer = num_layers\n",
    "        self.nhid = num_hidden\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.gc = nn.ModuleList([dglnn.SAGEConv(self.nfeat if i==0 else self.nhid, self.nhid, 'pool') for i in range(self.nlayer)])\n",
    "        self.bn = nn.ModuleList([nn.LayerNorm(self.nhid) for i in range(self.nlayer)])\n",
    "        self.relu = nn.ModuleList([nn.ReLU() for i in range(self.nlayer)])\n",
    "        self.pooling = MaxPooling()\n",
    "        self.fc = nn.Linear(self.nhid, 1)\n",
    "        self.fc1 = nn.Linear(self.nhid, self.nhid)\n",
    "        self.dropout = nn.ModuleList([nn.Dropout(self.dropout_ratio) for i in range(self.nlayer)])\n",
    "\n",
    "    def forward_single_model(self, g, features):\n",
    "        x = self.relu[0](self.bn[0](self.gc[0](g, features)))\n",
    "        x = self.dropout[0](x)\n",
    "        for i in range(1,self.nlayer):\n",
    "            x = self.relu[i](self.bn[i](self.gc[i](g, x)))\n",
    "            x = self.dropout[i](x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.forward_single_model(g, features)\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = x\n",
    "            x = self.pooling(g, x)\n",
    "            x = self.fc1(x)\n",
    "            return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading Data.\n",
    "\n",
    "Next, we will finish loading the data and learn about the size of the Training and Testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training Set.\n",
      "Processing Testing Set.\n",
      "Train Dataset Size: 20732\n",
      "Testing Dataset Size: 5173\n",
      "Attribute tensor shape: 26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nn_meter.dataset import gnn_dataloader\n",
    "\n",
    "target_device = \"cortexA76cpu_tflite21\"\n",
    "\n",
    "print(\"Processing Training Set.\")\n",
    "train_set = gnn_dataloader.GNNDataset(train=True, device=target_device) \n",
    "print(\"Processing Testing Set.\")\n",
    "test_set = gnn_dataloader.GNNDataset(train=False, device=target_device)\n",
    "\n",
    "train_loader = gnn_dataloader.GNNDataloader(train_set, batchsize=1 , shuffle=True)\n",
    "test_loader = gnn_dataloader.GNNDataloader(test_set, batchsize=1, shuffle=False)\n",
    "print('Train Dataset Size:', len(train_set))\n",
    "print('Testing Dataset Size:', len(test_set))\n",
    "print('Attribute tensor shape:', next(train_loader)[1].ndata['h'].size(1))\n",
    "ATTR_COUNT = next(train_loader)[1].ndata['h'].size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run and Test\n",
    "\n",
    "We can run the model and evaluate it now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  0 ]:  Training accuracy within 10%:  21.999807061547365  %.\n",
      "[Epoch  1 ]:  Training accuracy within 10%:  27.725255643449742  %.\n",
      "[Epoch  2 ]:  Training accuracy within 10%:  30.228632066370825  %.\n",
      "[Epoch  3 ]:  Training accuracy within 10%:  31.357322014277443  %.\n",
      "[Epoch  4 ]:  Training accuracy within 10%:  33.06000385876906  %.\n",
      "[Epoch  5 ]:  Training accuracy within 10%:  34.917036465367545  %.\n",
      "[Epoch  6 ]:  Training accuracy within 10%:  36.48466139301563  %.\n",
      "[Epoch  7 ]:  Training accuracy within 10%:  39.070036658306  %.\n",
      "[Epoch  8 ]:  Training accuracy within 10%:  40.10708084121165  %.\n",
      "[Epoch  9 ]:  Training accuracy within 10%:  41.530001929384525  %.\n",
      "[Epoch  10 ]:  Training accuracy within 10%:  43.26162454177118  %.\n",
      "[Epoch  11 ]:  Training accuracy within 10%:  45.34053636889832  %.\n",
      "[Epoch  12 ]:  Training accuracy within 10%:  48.45166891761528  %.\n",
      "[Epoch  13 ]:  Training accuracy within 10%:  50.945398417904684  %.\n",
      "[Epoch  14 ]:  Training accuracy within 10%:  54.5774647887324  %.\n",
      "[Epoch  15 ]:  Training accuracy within 10%:  56.08238471927455  %.\n",
      "[Epoch  16 ]:  Training accuracy within 10%:  59.54562994404785  %.\n",
      "[Epoch  17 ]:  Training accuracy within 10%:  62.41076596565696  %.\n",
      "[Epoch  18 ]:  Training accuracy within 10%:  63.65521898514373  %.\n",
      "[Epoch  19 ]:  Training accuracy within 10%:  64.6826162454177  %.\n",
      "Testing accuracy within 10%:  60.042528513435144  %.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA.\")\n",
    "# device = \"cpu\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Start Training\n",
    "load_model = False\n",
    "if load_model:\n",
    "    model = GNN(ATTR_COUNT, 3, 400, 0.1).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
    "    checkpoint = torch.load('LatencyGNN.pt')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # EPOCHS = checkpoint['epoch']\n",
    "    EPOCHS = 0\n",
    "    loss_func = checkpoint['loss']\n",
    "else:\n",
    "    model = GNN(ATTR_COUNT, 3, 400, 0.1).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=4e-4)\n",
    "    EPOCHS=20\n",
    "    loss_func = nn.L1Loss()\n",
    "\n",
    "lr_scheduler = CosineAnnealingLR(opt, T_max=EPOCHS)\n",
    "loss_sum = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_length = len(train_set)\n",
    "    tran_acc_ten = 0\n",
    "    loss_sum = 0 \n",
    "    # latency, graph, types, flops\n",
    "    for batched_l, batched_g in train_loader:\n",
    "        opt.zero_grad()\n",
    "        batched_l = batched_l.to(device).float()\n",
    "        batched_g = batched_g.to(device)\n",
    "        batched_f = batched_g.ndata['h'].float()\n",
    "        logits = model(batched_g, batched_f)\n",
    "        for i in range(len(batched_l)):\n",
    "            pred_latency = logits[i].item()\n",
    "            prec_latency = batched_l[i].item()\n",
    "            if (pred_latency >= 0.9 * prec_latency) and (pred_latency <= 1.1 * prec_latency):\n",
    "                tran_acc_ten += 1\n",
    "        # print(\"true latency: \", batched_l)\n",
    "        # print(\"Predict latency: \", logits)\n",
    "        batched_l = torch.reshape(batched_l, (-1 ,1))\n",
    "        loss = loss_func(logits, batched_l)\n",
    "        loss_sum += loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    lr_scheduler.step()\n",
    "    print(\"[Epoch \", epoch, \"]: \", \"Training accuracy within 10%: \", tran_acc_ten / train_length * 100, \" %.\")\n",
    "    # print('Learning Rate:', lr_scheduler.get_last_lr())\n",
    "    # print('Loss:', loss_sum / train_length)\n",
    "\n",
    "# Save The Best Model\n",
    "torch.save({\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': opt.state_dict(),\n",
    "    'loss': loss_func,\n",
    "}, 'LatencyGNN.pt')\n",
    "\n",
    "# Start Testing\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    test_length = len(test_set)\n",
    "    test_acc_ten = 0\n",
    "    for batched_l, batched_g in test_loader:\n",
    "        batched_l = batched_l.to(device).float()\n",
    "        batched_g = batched_g.to(device)\n",
    "        batched_f = batched_g.ndata['h'].float()\n",
    "        result = model(batched_g, batched_f)\n",
    "        if (result.item() >= 0.9 * batched_l.item()) and (result.item() <= 1.1 * batched_l.item()):\n",
    "            test_acc_ten += 1\n",
    "        acc = (abs(result.item() - batched_l.item()) / batched_l.item()) * 100\n",
    "        count += 1\n",
    "    print(\"Testing accuracy within 10%: \", test_acc_ten / test_length * 100, \" %.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0238da245144306487e61782d9cba9bf2e5e19842e5054371ac0cfbea9be2b57"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
